---
output:
  pdf_document:
    fig_caption: no
    number_sections: no
    toc: yes
    toc_depth: 2
    # github_document:
    # html_preview: yes
    # toc: yes
    # toc_depth: 2
editor_options: 
  chunk_output_type: inline
---

Here I varied the sample size of trials from 20 to 150 in increments of 10 based on the code from Rousselet (2023). 

# Dependencies
```{r setup, message=FALSE}
library(ggplot2)
library(tibble)
library(cowplot)
library(beepr)
library(Rfast)
library(changepoint)
library(mcp)
library(rjags)
library(mutoss)
library(ecp)
source("./code/functions.R")
source("./code/theme_gar.txt")
# Edit `one_over_f` function from `primer` package to control variance (Stevens, 2009). 
# Original function is available on [GitHub](https://github.com/HankStevens/primer).
# Copyright Hank Stevens.
source("./code/one_over_f.R")
# Load template: true onset = 160 ms, F=81, max at F=126
source("./code/erp_template.R")
# R version of Matlab code from Yeung et al. 2004
source("./code/eeg_noise.R")
# Lodaing the code that gives median instead of mean values in mcp summary table
source("./code/mcp_median_function.R")
# to use with eeg_noise function
meanpower <- unlist(read.table("./code/meanpower.txt"))
```

# Simulation: vary sample size

```{r eval=FALSE, message=TRUE, warning=FALSE, include=FALSE}

# Saving function to save simulation results incrementally every 100 simulation iterations
saving_results <- function(iteration, simres.cs, simres.fdr, simres.cp, simres.pelt, simres.mcp, simres.ecp) {
  filename <- sprintf("./vary_n_sim_incr_save_data/main_vary_n_iter_%d.RData", iteration)
  save(simres.cs, simres.fdr, simres.cp, simres.pelt, simres.mcp, simres.ecp, file = filename)
}

set.seed(666) 
aath <- 0.05 # arbitrary alpha threshold
nsim <- 10000 # simulation iterations
nboot <- 2 # number of permutation samples
srate <- 500 # sampling rate in Hz
n_vec <- seq(20,150,10) 
n_length <- length(n_vec)
n_max <- max(n_vec)
inc.step <- 500

# Matrices for each method
simres.cp <- matrix(NA, nrow = n_length, ncol = nsim)
simres.fdr <- matrix(NA, nrow = n_length, ncol = nsim)
simres.cs <- matrix(NA, nrow = n_length, ncol = nsim)
simres.mcp <- matrix(NA, nrow = n_length, ncol = nsim)
simres.pelt <- matrix(NA, nrow = n_length, ncol = nsim)
simres.ecp <- matrix(NA, nrow = n_length, ncol = nsim)
simres.mcp.mean <- matrix(NA, nrow = n_length, ncol = nsim)

outvar <- 1 # noise variance
cond1_all <- matrix(0, nrow = n_max, ncol = Nf)
cond2_all <- matrix(0, nrow = n_max, ncol = Nf)

for(S in 1:nsim){
  
  sim.counter(S, nsim, inc = inc.step)
  
  # Generate all trials
  for(T in 1:n_max){
    cond2_all[T,] <- temp2 + eeg_noise(frames = Nf, srate = srate, outvar = outvar, meanpower)
    cond1_all[T,] <- temp1 + eeg_noise(frames = Nf, srate = srate, outvar = outvar, meanpower) 
  }
  
  for(N in 1:n_length){
    
    Nt <- n_vec[N]
    
    # downsample to current size
    cond2 <- cond2_all[1:Nt,]
    cond1 <- cond1_all[1:Nt,]
    
    # t-tests
    ori.t2 <- vector(mode = "numeric", length = Nf)
    for(F in 1:Nf){
      ori.t2[F] <- t.test(cond1[,F], cond2[,F])$statistic^2
    }
    
    #######################################
    
    # fit change point model
    res <- cpt.meanvar(ori.t2, method = "BinSeg", Q=2)
    simres.cp[N,S] <- Xf[res@cpts[1]]
    
    #######################################
    
    # Fit PELT with a penalty multiplier of 30
    res.pelt <- cpt.meanvar(ori.t2, method = "PELT", penalty = "Manual", pen.value = 30*log(length(ori.t2)))
    simres.pelt[N,S] <- Xf[res.pelt@cpts[1]]
    
    #######################################
    
    # Fit mcp model
    df <- tibble(x = Xf, y = ori.t2)
    model <- list(
      y ~ 1 + sigma(1),
        ~ 0 + x + sigma(1)
    )
    
    prior <- list(
      cp_1 = "dunif(100, 250)" # Change point expected between 100 and 250 ms
    )
  
    fit <- mcp(model, prior = prior, data = df, cores = 3, chains = 3)
  
    summary.fit.median <- summary.mcpfit.median(fit)
    simres.mcp[N,S] <- round(summary.fit.median[1,2],0)
  
    # Fitting the same model but for the mean function to compare to median
    summary.fit.mean <- mcp:::summary.mcpfit(fit)
    simres.mcp.mean[N,S] <- round(summary.fit.mean[1,2],0)
  
    ######################################
    
    # Make permutation table of t values 
    perm.t2 <- permtdist(cond1, cond2, Nt, Nf, nboot = nboot)^2
    perm.th <- apply(perm.t2, 2, quantile, probs = 1-aath)
    
    # FDR -----
    perm.pvals <- vector(mode = "numeric", length = Nf)
    for(F in 1:Nf){
      perm.pvals[F] <- (sum(perm.t2[,F] >= ori.t2[F]) + 1) / (nboot + 1)
    }
    fdr.pvals <- p.adjust(perm.pvals, method = "fdr")
    simres.fdr[N,S] <- find_onset(fdr.pvals <= aath, Xf)
    
    ######################################
    
    # cluster-sum statistics -----
    cmap <- cluster.make(perm.pvals <= aath)
    perm.max.sums <- vector(mode = "numeric", length = nboot)
    for(B in 1:nboot){
      # threshold permutation t2 values and form clusters
      perm.cmap <- cluster.make(perm.t2[B,] <= perm.th)  
      perm.max.sums[B] <- max(cluster.sum(values = perm.t2[B,], cmap = perm.cmap))
    }
    # cluster sum threshold
    cs.th <- quantile(perm.max.sums, probs = 1-aath)
    # cluster test
    cs.test <- cluster.test(values = ori.t2, cmap = cmap, cs.th)
    simres.cs[N,S] <- find_onset(cs.test, Xf)
    
    #######################################
    
    # Fit non-parametric e.cp3o_delta from ecp package
    ori.t2 <- matrix(ori.t2, ncol = 1) # ecp only accepts matrices 
    
    # Fit ecp cp3o_delta model
    result_cp3o_delta <- e.cp3o_delta(Z = ori.t2, K = 8, alpha = 1)
    simres.ecp[N,S] <- get_earliest_cp(result_cp3o_delta$estimates, Xf)
  }
  
  # Check if we need to save the results now
  if (S %% 500 == 0 || S == nsim) {
    saving_results(S, simres.cs, simres.fdr, simres.cp, simres.pelt, simres.mcp, simres.ecp)
  }
}
```


## Combining saved files
```{r}
setwd("./vary_n_sim_incr_save_data/")

# List all .RData files in the directory
files <- list.files(pattern = "\\.RData$")

combined_simres_cs <- list()
combined_simres_fdr <- list()
combined_simres_cp <- list()
combined_simres_pelt <- list()
combined_simres_mcp <- list()
combined_simres_ecp <- list()

for (file in files) {
  load(file)
  
  # Print dimensions to check consistency
  print(paste("File:", file, "simres.cs Dimensions:", dim(simres.cs)))
  
  combined_simres_cs[[file]] <- simres.cs
  combined_simres_fdr[[file]] <- simres.fdr
  combined_simres_cp[[file]] <- simres.cp
  combined_simres_pelt[[file]] <- simres.pelt
  combined_simres_mcp[[file]] <- simres.mcp
  combined_simres_ecp[[file]] <- simres.ecp
}

simres.cs <- do.call(rbind, combined_simres_cs)
simres.fdr <- do.call(rbind, combined_simres_fdr)
simres.cp <- do.call(rbind, combined_simres_cp)
simres.pelt <- do.call(rbind, combined_simres_pelt)
simres.mcp <- do.call(rbind)
```

### Merging all of the files into 1
```{r}
# Set the directory containing the .RData files
setwd("./vary_n_sim_incr_save_data/")

# List all .RData files in the directory
files <- list.files(pattern = "\\.RData$")

combined_simres_cs <- list()
combined_simres_fdr <- list()
combined_simres_cp <- list()
combined_simres_pelt <- list()
combined_simres_mcp <- list()
combined_simres_ecp <- list()

for (file in files) {
  load(file)
  combined_simres_cs[[file]] <- simres.cs
  combined_simres_fdr[[file]] <- simres.fdr
  combined_simres_cp[[file]] <- simres.cp
  combined_simres_pelt[[file]] <- simres.pelt
  combined_simres_mcp[[file]] <- simres.mcp
  combined_simres_ecp[[file]] <- simres.ecp
}


simres.cs <- do.call(rbind, combined_simres_cs)
simres.fdr <- do.call(rbind, combined_simres_fdr)
simres.cp <- do.call(rbind, combined_simres_cp)
simres.pelt <- do.call(rbind, combined_simres_pelt)
simres.mcp <- do.call(rbind, combined_simres_mcp)
simres.ecp <- do.call(rbind, combined_simres_ecp)

# Save the combined datasets into a single .RData file
save(simres.cs, simres.fdr, simres.cp, simres.pelt, simres.mcp, simres.ecp,
     file = "./main_sim_vary_n.RData")
```

## Results

Plot results as a function of sample size.

### Compute summary statistics
```{r}
load(file = "./vary_n_sim_incr_save_data/main_sim_vary_n.RData")

n_vec <- seq(20,150,10) 
n_length <- length(n_vec)

res.bias <- matrix(0, nrow = 6, ncol = n_length) 
res.mae <- matrix(0, nrow = 6, ncol = n_length)
res.var <- matrix(0, nrow = 6, ncol = n_length)
res.pte <- matrix(0, nrow = 6, ncol = n_length)
res.p40 <- matrix(0, nrow = 6, ncol = n_length)

for(N in 1:n_length){
  #Bias
  res.bias[1,N] <- median(simres.fdr[N,], na.rm = TRUE) - true_onset
  res.bias[2,N] <- median(simres.cs[N,], na.rm = TRUE) - true_onset
  res.bias[3,N] <- median(simres.cp[N,], na.rm = TRUE) - true_onset
  res.bias[4,N] <- median(simres.mcp[N,], na.rm = TRUE) - true_onset
  res.bias[5,N] <- median(simres.ecp[N,], na.rm = TRUE) - true_onset
  res.bias[6,N] <- median(simres.pelt[N,], na.rm = TRUE) - true_onset
  
  #Mean absolute error 
  res.mae[1,N] <- mean(abs(simres.fdr[N,] - true_onset), na.rm = TRUE)
  res.mae[2,N] <- mean(abs(simres.cs[N,] - true_onset), na.rm = TRUE)
  res.mae[3,N] <- mean(abs(simres.cp[N,] - true_onset), na.rm = TRUE)
  res.mae[4,N] <- mean(abs(simres.mcp[N,] - true_onset), na.rm = TRUE)
  res.mae[5,N] <- mean(abs(simres.ecp[N,] - true_onset), na.rm = TRUE)
  res.mae[6,N] <- mean(abs(simres.pelt[N,] - true_onset), na.rm = TRUE)
  
  #Variance
  res.var[1,N] <- var(simres.fdr[N,], na.rm = TRUE)
  res.var[2,N] <- var(simres.cs[N,], na.rm = TRUE)
  res.var[3,N] <- var(simres.cp[N,], na.rm = TRUE)
  res.var[4,N] <- var(simres.mcp[N,], na.rm = TRUE)
  res.var[5,N] <- var(simres.ecp[N,], na.rm = TRUE)
  res.var[6,N] <- var(simres.pelt[N,], na.rm = TRUE)
  
  #Proportion too early
  res.pte[1,N] <- mean((simres.fdr[N,] - true_onset) < 0, na.rm = TRUE)
  res.pte[2,N] <- mean((simres.cs[N,] - true_onset) < 0, na.rm = TRUE)
  res.pte[3,N] <- mean((simres.cp[N,] - true_onset) < 0, na.rm = TRUE)
  res.pte[4,N] <- mean((simres.mcp[N,] - true_onset) < 0, na.rm = TRUE)
  res.pte[5,N] <- mean((simres.ecp[N,] - true_onset) < 0, na.rm = TRUE)
  res.pte[6,N] <- mean((simres.pelt[N,] - true_onset) < 0, na.rm = TRUE)
  
  #Underestimations of at least 40 ms
  res.p40[1,N] <- mean((simres.fdr[N,] - true_onset) <= -40, na.rm = TRUE)
  res.p40[2,N] <- mean((simres.cs[N,] - true_onset) <= -40, na.rm = TRUE)
  res.p40[3,N] <- mean((simres.cp[N,] - true_onset) <= -40, na.rm = TRUE)
  res.p40[4,N] <- mean((simres.mcp[N,] - true_onset) <= -40, na.rm = TRUE)
  res.p40[5,N] <- mean((simres.ecp[N,] - true_onset) <= -40, na.rm = TRUE)
  res.p40[6,N] <- mean((simres.pelt[N,] - true_onset) <= -40, na.rm = TRUE)
}
```

### Make figures 
#### Bias
```{r fig.height=6, fig.width=8}
# Colour palette from http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/
categ.palette <- c("FDR" = "#000000",
                   "Cluster sum" = "#009E73",
                   "BinSeg" = "#E69F00",
                   "mcp" = "#D55E00",
                   "cp3o_delta" = "#0072B2",
                   "PELT" = "#CC79A7")

df2 <- tibble(res = as.vector(res.bias),
             n = rep(n_vec, each = 6),
             method = rep(c("FDR", "Cluster sum", "BinSeg", "mcp", "cp3o_delta", "PELT"), n_length)
)
library(dplyr)
# Loading GAR's results for cluster sum and FDR
df_filtered <- df %>% 
  filter(method %in% c("FDR", "Cluster sum"))

# Left join df2 with df_filtered to fill missing 'res' values
df2 <- df2 %>%
  left_join(df_filtered, by = c("n", "method"), suffix = c("", ".y")) %>%
  mutate(res = coalesce(res, res.y)) %>%
  select(-res.y)


p <- ggplot(df2, aes(x = n, y = res, group = method, colour = method)) + theme_gar +
  geom_point() +
  geom_line() +
  scale_colour_manual(values = categ.palette) +
  labs(x = "Sample size", y = "Bias") +
  theme(legend.position = c(.8, .2)) +
  scale_x_continuous(breaks = n_vec) +
  scale_y_continuous(breaks = seq(-40,70,10), limits = c(-40, 70))
p

p.bias <- p

# ggsave(filename = "./figures/eeg_varyn_bias.pdf", width = 10, height = 5)
```

#### MAE
```{r fig.height=6, fig.width=8}
categ.palette <- c("FDR" = "#000000",
                   "Cluster sum" = "#009E73",
                   "BinSeg" = "#E69F00",
                   "mcp" = "#D55E00",
                   "cp3o_delta" = "#0072B2",
                   "PELT" = "#CC79A7")

df2 <- tibble(res = as.vector(res.mae),
             n = rep(n_vec, each = 6),
             method = rep(c("FDR", "Cluster sum", "BinSeg", "mcp", "cp3o_delta", "PELT"), n_length)
)


df_filtered <- df %>% 
  filter(method %in% c("FDR", "Cluster sum"))

# Left join df2 with df_filtered to fill missing 'res' values
df2 <- df2 %>%
  left_join(df_filtered, by = c("n", "method"), suffix = c("", ".y")) %>%
  mutate(res = coalesce(res, res.y)) %>%
  select(-res.y)

p.mae <- ggplot(df2, aes(x = n, y = res, group = method, colour = method)) + theme_gar +
  geom_point() +
  geom_line() +
  scale_colour_manual(values = categ.palette) +
  ylab("MAE") +
  scale_x_continuous(breaks = n_vec) + theme(legend.position = "none")
p.mae
```

#### Variance
```{r fig.height=6, fig.width=8}
categ.palette <- c("FDR" = "#000000",
                   "Cluster sum" = "#009E73",
                   "BinSeg" = "#E69F00",
                   "mcp" = "#D55E00",
                   "cp3o_delta" = "#0072B2",
                   "PELT" = "#CC79A7")

df2 <- tibble(res = as.vector(res.var),
             n = rep(n_vec, each = 6),
             method = rep(c("FDR", "Cluster sum", "BinSeg", "mcp", "cp3o_delta", "PELT"), n_length)
)

df_filtered <- df %>% 
  filter(method %in% c("FDR", "Cluster sum"))

# Left join df2 with df_filtered to fill missing 'res' values
df2 <- df2 %>%
  left_join(df_filtered, by = c("n", "method"), suffix = c("", ".y")) %>%
  mutate(res = coalesce(res, res.y)) %>%
  select(-res.y)

p <- ggplot(df2, aes(x = n, y = res, group = method, colour = method)) + theme_gar +
  geom_point(show.legend = FALSE) +
  geom_line(show.legend = FALSE) +
  scale_colour_manual(values = categ.palette) +
  labs(x = "Sample size", y = "Variance") +
  theme(legend.position = c(.8, .8)) +
  scale_x_continuous(breaks = n_vec) +
  scale_y_continuous(breaks = seq(0,13000,3000))
  # scale_y_continuous(breaks = seq(0,70,10))
p

p.var <- p
# ggsave(filename = "./figures/eeg_varyn_var.pdf", width = 10, height = 5)
```


#### Proportion too early

```{r fig.height=6, fig.width=8}
categ.palette <- c("FDR" = "#000000",
                   "Cluster sum" = "#009E73",
                   "BinSeg" = "#E69F00",
                   "mcp" = "#D55E00",
                   "cp3o_delta" = "#0072B2",
                   "PELT" = "#CC79A7")

df2 <- tibble(res = as.vector(res.pte),
             n = rep(n_vec, each = 6),
             method = rep(c("FDR", "Cluster sum", "BinSeg", "mcp", "cp3o_delta", "PELT"), n_length)
)

df_filtered <- df %>% 
  filter(method %in% c("FDR", "Cluster sum"))

# Left join df2 with df_filtered to fill missing 'res' values
df2 <- df2 %>%
  left_join(df_filtered, by = c("n", "method"), suffix = c("", ".y")) %>%
  mutate(res = coalesce(res, res.y)) %>%
  select(-res.y)

ggplot(df2, aes(x = n, y = res, group = method, colour = method)) + theme_gar +
  geom_point(show.legend = FALSE) +
  geom_line(show.legend = FALSE) +
  scale_colour_manual(values = categ.palette) +
  ylab("Proportion too early") +
  scale_x_continuous(breaks = n_vec)
```

Rousselet GA (2023) Using cluster-based permutation tests to estimate MEG/EEG onsets: how bad is it? bioRxiv. https://doi.org/10.1101/2023.11.13.566864